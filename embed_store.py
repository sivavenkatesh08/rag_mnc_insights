import os
from pathlib import Path
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from scripts.clean_chunk_data import load_all_transcripts, BASE_DIR

# ğŸ“ Output path for FAISS index
OUTPUT_DIR = BASE_DIR.parent / "outputs"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
INDEX_PATH = OUTPUT_DIR / "mnc_faiss_index"

# ğŸ§  Load transcripts
print("ğŸ“š Loading and chunking transcripts...")
docs = load_all_transcripts(BASE_DIR)
print(f"âœ… Loaded {len(docs)} chunks.")

# ğŸ” Embedding model
print("ğŸ”§ Creating embeddings...")
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# ğŸ—ƒï¸ Create FAISS index
print("ğŸ’¾ Creating FAISS index...")
vectorstore = FAISS.from_documents(docs, embedding_model)
vectorstore.save_local(str(INDEX_PATH))
print(f"âœ… FAISS index saved to: {INDEX_PATH}")
